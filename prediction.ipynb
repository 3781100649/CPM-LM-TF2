{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 依赖：\n",
    "# !pip install sentencepiece\n",
    "# !pip install jieba\n",
    "# !pip install regex\n",
    "# !pip install tensorflow\n",
    "# !pip install tensorflow-hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "\n",
    "from gpt2_tokenizer import GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer(\n",
    "    'CPM-Generate/bpe_3w_new/vocab.json',\n",
    "    'CPM-Generate/bpe_3w_new/merges.txt',\n",
    "    model_file='CPM-Generate/bpe_3w_new/chinese_vocab.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt = hub.load('./cpm-lm-tf2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(tokenizer, gpt, sentence, number=1, length=20):\n",
    "    inputs = tf.constant([tokenizer.encode(sentence)] * number, dtype=tf.int64)\n",
    "    length = tf.constant(length, dtype=tf.int64)\n",
    "    ret = gpt.signatures['serving_default'](inp=inputs, length=length)['output_0']\n",
    "    return [\n",
    "        tokenizer.decode(s).replace(' ', '')\n",
    "        for s in ret.numpy()\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 英文问答例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.693 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "默写英文:\n",
      "狗dog\n",
      "猫cat\n",
      "鸟southern\n",
      "萤火虫\n",
      "--------------------\n",
      "默写英文:\n",
      "狗dog\n",
      "猫cat\n",
      "鸟bird\n",
      "马horse\n",
      "\n",
      "--------------------\n",
      "默写英文:\n",
      "狗dog\n",
      "猫cat\n",
      "鸟bird\n",
      "老虎stripper\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '默写英文：\\n狗dog\\n猫cat\\n鸟', 3, 10)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 默写古诗例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "默写古诗:\n",
      "白日依山尽,黄河入海流。\n",
      "床前明月光,疑是地上霜。\n",
      "举头望\n",
      "--------------------\n",
      "默写古诗:\n",
      "白日依山尽,黄河入海流。\n",
      "床前明月光,疑是地上霜。\n",
      "举头望\n",
      "--------------------\n",
      "默写古诗:\n",
      "白日依山尽,黄河入海流。\n",
      "床前明月光,疑是地上霜。\n",
      "举头望\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '默写古诗：\\n白日依山尽，黄河入海流。\\n床前明月光，', 3, 10)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 不同的角色对话生成例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "李大嘴:“各回各家,各找各妈!”\n",
      "佟掌柜:“朱儿,请你看好店!”\n",
      "郭芙蓉:\n",
      "--------------------\n",
      "李大嘴:“各回各家,各找各妈!”\n",
      "佟掌柜:“好啊!”\n",
      "老七:“笑话,我见过\n",
      "--------------------\n",
      "李大嘴:“各回各家,各找各妈!”\n",
      "佟掌柜:“他这个讨饭的,凭什么收你的银子,有地儿是\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '李大嘴：“各回各家，各找各妈！” \\n佟掌柜：“', 3, 20)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "李大嘴:“各回各家,各找各妈!”\n",
      "白展堂:“问联吧,到处都是。”\n",
      "佟湘玉\n",
      "--------------------\n",
      "李大嘴:“各回各家,各找各妈!”\n",
      "白展堂:“李大嘴,背上背的啥?”\n",
      "李大嘴\n",
      "--------------------\n",
      "李大嘴:“各回各家,各找各妈!”\n",
      "白展堂:“那正好,我告禀绿竹林,你要所有人,全都走\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '李大嘴：“各回各家，各找各妈！” \\n白展堂：“', 3, 20)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "李大嘴:“各回各家,各找各妈!”\n",
      "莫小贝:“好,你走吧!”\n",
      "管家:“那他...\n",
      "--------------------\n",
      "李大嘴:“各回各家,各找各妈!”\n",
      "莫小贝:“小眉姐,你是几个意思?”\n",
      "佟湘玉\n",
      "--------------------\n",
      "李大嘴:“各回各家,各找各妈!”\n",
      "莫小贝:“那我看贾宝玉了!(众人笑)贾宝玉那能跟我走\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '李大嘴：“各回各家，各找各妈！” \\n莫小贝：“', 3, 20)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "李大嘴:“各回各家,各找各妈!”\n",
      "李白:“陛下的江山我的爱,轰轰烈烈!”\n",
      "孟姜\n",
      "--------------------\n",
      "李大嘴:“各回各家,各找各妈!”\n",
      "李白:“阿阿,太白一去不复返,不信你问月亮。”\n",
      "--------------------\n",
      "李大嘴:“各回各家,各找各妈!”\n",
      "李白:“哈哈,你真是太不厚道了,你完全可以喊我李大嘴\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '李大嘴：“各回各家，各找各妈！” \\n李白：“', 3, 20)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 问答的例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "中国的首都是北京\n",
      "日本的首都是东京\n",
      "美国的首都是华盛顿\n",
      "加拿大\n",
      "--------------------\n",
      "中国的首都是北京\n",
      "日本的首都是东京\n",
      "美国的首都是华盛顿\n",
      "英国\n",
      "--------------------\n",
      "中国的首都是北京\n",
      "日本的首都是东京\n",
      "美国的首都是华盛顿\n",
      "<eod>\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '中国的首都是北京\\n日本的首都是东京\\n美国的首都是', 3, 3)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "李白所在朝代是唐\n",
      "李清照所在朝代是宋\n",
      "唐伯虎所在朝代是元\n",
      "--------------------\n",
      "李白所在朝代是唐\n",
      "李清照所在朝代是宋\n",
      "唐伯虎所在朝代是明\n",
      "--------------------\n",
      "李白所在朝代是唐\n",
      "李清照所在朝代是宋\n",
      "唐伯虎所在朝代是明\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '李白所在朝代是唐\\n李清照所在朝代是宋\\n唐伯虎所在朝代是', 3, 1)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 算数例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1+1=2\n",
      "2+2=4\n",
      "3+3=6\n",
      "4+4=12\n",
      "--------------------\n",
      "1+1=2\n",
      "2+2=4\n",
      "3+3=6\n",
      "4+4=8\n",
      "--------------------\n",
      "1+1=2\n",
      "2+2=4\n",
      "3+3=6\n",
      "4+4=8\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '1+1=2\\n2+2=4\\n3+3=6\\n4+4=', 3, 1)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1+1=2\n",
      "1+2=3\n",
      "1+3=4\n",
      "1+4=5\n",
      "--------------------\n",
      "1+1=2\n",
      "1+2=3\n",
      "1+3=4\n",
      "1+4=5\n",
      "--------------------\n",
      "1+1=2\n",
      "1+2=3\n",
      "1+3=4\n",
      "1+4=8\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '1+1=2\\n1+2=3\\n1+3=4\\n1+4=', 3, 1)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ???的例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "惊雷这通天修为\n",
      "天塌地陷紫金锤\n",
      "紫电这玄真火焰\n",
      "紫雷吼着万妖王\n",
      "魔风这魔音响九天\n",
      "紫尘这雾清天下\n",
      "但是这邪剑\n",
      "--------------------\n",
      "惊雷这通天修为\n",
      "天塌地陷紫金锤\n",
      "紫电这玄真火焰\n",
      "紫金斧一挥天地灭\n",
      "霹雳剑一挥天地裂\n",
      "......\n",
      "<eod>诗词:画里闲空\n",
      "--------------------\n",
      "惊雷这通天修为\n",
      "天塌地陷紫金锤\n",
      "紫电这玄真火焰\n",
      "金弧子传千年斩首钢瓶\n",
      "火蛇钻裂风雷斧\n",
      "着一身银甲手拿银锤\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '''惊雷这通天修为\n",
    "天塌地陷紫金锤\n",
    "紫电这玄真火焰\n",
    "''', 3, 30)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 写作文例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "爱情是盲目的所以我很少会主动去谈恋爱我是个很现实的人而且目前为止我都不清楚我自己想要的是什么身边好友来来往\n",
      "--------------------\n",
      "爱情是什么感觉?-爱情1.半夜的时候,迷迷糊糊的时候。昏昏沉沉的时候,听见电话响,他的声音,都会不自觉的兴奋\n",
      "--------------------\n",
      "爱情是以什么样的方式产生,是否可以以这样的方式相爱,相爱后是否可以长相厮守,还有有没有什么其它的态度等等等等...\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '''爱情是''', 3, 50)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一时黛玉进了荣府,下了车。众嬷嬷引着,便往东转弯,穿过一个东西的穿堂,向南大厅之后,仪门内大院落,上面五间大正房,两边厢房鹿顶耳房钻山,四通八达,轩昂壮丽,比贾母处不同。黛玉便知这方是正经正内室,一条大甬路,直接出大门的。只见宝玉的小丫鬟麝月,一个人在甬路东头刚舀了一瓢汤先端来了,黛玉笑道:“这汤可以解渴。”说着,便伸手想接。麝月笑道:“亲奶奶那边不是茶水,恐怕小姐要犯头疼。我给你另盛一碗来。”黛玉因吃了药,怯弱不胜,便知今日是遇到的贵人了,便也顾不得客气,接了来,一气吃完。这时人已近了东首正房大厅,黛玉方知迎面而来的人竟是林妹妹。众人不觉都愣住了,林妹妹扶了林黛玉的手笑道:“他看咱\n",
      "--------------------\n",
      "一时黛玉进了荣府,下了车。众嬷嬷引着,便往东转弯,穿过一个东西的穿堂,向南大厅之后,仪门内大院落,上面五间大正房,两边厢房鹿顶耳房钻山,四通八达,轩昂壮丽,比贾母处不同。黛玉便知这方是正经正内室,一条大甬路,直接出大门的。五间大房,北朝南正房五间,东西各有耳房两个,南房三间,贾母王夫人住左边西炕,贾母王夫人住右边,贾母陪着贾母王夫人同住,正好两屋宇相对。东配房北房三间,西边配房东西各五间,四个人在那里住。只见那些媳妇丫鬟丫环婆子们,手里拿着簸箕⁇帚,在山石后头,竹林内旁边,土坡凹处,找寻出路土坡之外,并没甚事,正谈说道:“太太的婢子雪雁,早投奔二爷去了。我说二爷对他再好,二\n",
      "--------------------\n",
      "一时黛玉进了荣府,下了车。众嬷嬷引着,便往东转弯,穿过一个东西的穿堂,向南大厅之后,仪门内大院落,上面五间大正房,两边厢房鹿顶耳房钻山,四通八达,轩昂壮丽,比贾母处不同。黛玉便知这方是正经正内室,一条大甬路,直接出大门的。黛玉适才搭姊妹屋住,现在看了父亲是客,自己是主,她的外祖母是管贾母衣帽的凤姐,而贾母只比她大几岁,按外祖母给她的荣府的名字,是正妻的孙女儿。即使贾母的位分高过她十倍,这一姓很可能还是姨太太。黛玉看到自己的外祖母,自然不觉心中凄楚,只是低头站着,可巧早有小丫头打扫出一所客厅来,擦得干干净净,铺着地毡,也做了一席葛布。黛玉在贾母处住了两年,这第一抹灯光的这里睡了两年,才看了一半,如今早有小丫头把四周房子里的\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '''一时黛玉进了荣府，下了车。众嬷嬷引着，便往东转弯，穿过一个东西的穿堂，向南大厅之后，仪门内大院落，上面五间大正房，两边厢房鹿顶耳房钻山，四通八达，轩昂壮丽，比贾母处不同。黛玉便知这方是正经正内室，一条大甬路，直接出大门的。''', 3, 200)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对话例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:“今天我想吃火锅”\n",
      "B:“好啊”\n",
      "A:“那就火锅”\n",
      "B:“那我吃什么?”\n",
      "A:“随便”\n",
      "B:“......”\n",
      "--------------------\n",
      "A:“今天我想吃火锅”\n",
      "B:“恩,这个,嘿嘿,如果你愿意,我请你吃饭”\n",
      "A:“那这样,就由我请你吃火锅,你看行不行?”\n",
      "B\n",
      "--------------------\n",
      "A:“今天我想吃火锅”\n",
      "B:“那我明天再煮吧”\n",
      "现在就是:\n",
      "C:“今天我想吃火锅”\n",
      "那么到底能不能明天煮呢?在在这里就帮你提示一下,明天\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '''A：“今天我想吃火锅”\n",
    "B：“''', 3, 50)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:“跟我一起去看电影吧”\n",
      "B:“我等你回来。”\n",
      "A:“我今天已经告诉过你了,我不会去看电影。”\n",
      "B:“好吧,我们就假设如果我\n",
      "--------------------\n",
      "A:“跟我一起去看电影吧”\n",
      "B:“那怎么可以”\n",
      "A:“上面有猫咪玩偶,对对对,就是它,能喝牛奶,特乖”\n",
      "B:“......”\n",
      "--------------------\n",
      "A:“跟我一起去看电影吧”\n",
      "B:“好啊好啊”\n",
      "A:“我请你吃饭吧”\n",
      "B:“那,一起看电影吧”\n",
      "只是一次正常的经历,不要想太多\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '''A：“跟我一起去看电影吧”\n",
    "B：“''', 3, 50)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对联例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对对联:\n",
      "天对地\n",
      "雨对风\n",
      "大陆对长空\n",
      "雷隐隐对雾蒙蒙\n",
      "开心大吉对万事亨通\n",
      "王老五对矮脚虎\n",
      "--------------------\n",
      "对对联:\n",
      "天对地\n",
      "雨对风\n",
      "大陆对长空\n",
      "雷隐隐对雾蒙蒙\n",
      "开心大吉对万事亨通\n",
      "王老五对张二嫂\n",
      "--------------------\n",
      "对对联:\n",
      "天对地\n",
      "雨对风\n",
      "大陆对长空\n",
      "雷隐隐对雾蒙蒙\n",
      "开心大吉对万事亨通\n",
      "王老五对金鼓锣\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '对对联：\\n天对地\\n雨对风\\n大陆对长空\\n雷隐隐对雾蒙蒙\\n开心大吉对万事亨通\\n王老五对', 3, 3)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对对联:\n",
      "天对地\n",
      "雨对风\n",
      "大陆对长空\n",
      "雷隐隐对雾蒙蒙\n",
      "开心大吉对万事亨通\n",
      "爱因斯坦对海森堡\n",
      "\n",
      "--------------------\n",
      "对对联:\n",
      "天对地\n",
      "雨对风\n",
      "大陆对长空\n",
      "雷隐隐对雾蒙蒙\n",
      "开心大吉对万事亨通\n",
      "爱因斯坦对双生子\n",
      "\n",
      "--------------------\n",
      "对对联:\n",
      "天对地\n",
      "雨对风\n",
      "大陆对长空\n",
      "雷隐隐对雾蒙蒙\n",
      "开心大吉对万事亨通\n",
      "爱因斯坦对爱迪生\n",
      "\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '对对联：\\n天对地\\n雨对风\\n大陆对长空\\n雷隐隐对雾蒙蒙\\n开心大吉对万事亨通\\n爱因斯坦对', 3, 4)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对对联:\n",
      "天对地\n",
      "雨对风\n",
      "大陆对长空\n",
      "雷隐隐对雾蒙蒙\n",
      "开心大吉对万事亨通\n",
      "李白对求笔架\n",
      "--------------------\n",
      "对对联:\n",
      "天对地\n",
      "雨对风\n",
      "大陆对长空\n",
      "雷隐隐对雾蒙蒙\n",
      "开心大吉对万事亨通\n",
      "李白对杜甫\n",
      "蔡\n",
      "--------------------\n",
      "对对联:\n",
      "天对地\n",
      "雨对风\n",
      "大陆对长空\n",
      "雷隐隐对雾蒙蒙\n",
      "开心大吉对万事亨通\n",
      "李白对杨玉环\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '对对联：\\n天对地\\n雨对风\\n大陆对长空\\n雷隐隐对雾蒙蒙\\n开心大吉对万事亨通\\n李白对', 3, 3)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对对联:\n",
      "天对地\n",
      "雨对风\n",
      "大陆对长空\n",
      "雷隐隐对雾蒙蒙\n",
      "开心大吉对万事亨通\n",
      "容嬷嬷对福禄寿\n",
      "--------------------\n",
      "对对联:\n",
      "天对地\n",
      "雨对风\n",
      "大陆对长空\n",
      "雷隐隐对雾蒙蒙\n",
      "开心大吉对万事亨通\n",
      "容嬷嬷对孙猴子\n",
      "--------------------\n",
      "对对联:\n",
      "天对地\n",
      "雨对风\n",
      "大陆对长空\n",
      "雷隐隐对雾蒙蒙\n",
      "开心大吉对万事亨通\n",
      "容嬷嬷对女仆\n",
      "\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '对对联：\\n天对地\\n雨对风\\n大陆对长空\\n雷隐隐对雾蒙蒙\\n开心大吉对万事亨通\\n容嬷嬷对', 3, 3)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对对联:\n",
      "天对地\n",
      "雨对风\n",
      "大陆对长空\n",
      "雷隐隐对雾蒙蒙\n",
      "开心大吉对万事亨通\n",
      "孙悟空对唐僧\n",
      "龙王\n",
      "--------------------\n",
      "对对联:\n",
      "天对地\n",
      "雨对风\n",
      "大陆对长空\n",
      "雷隐隐对雾蒙蒙\n",
      "开心大吉对万事亨通\n",
      "孙悟空对沙僧\n",
      "\n",
      "--------------------\n",
      "对对联:\n",
      "天对地\n",
      "雨对风\n",
      "大陆对长空\n",
      "雷隐隐对雾蒙蒙\n",
      "开心大吉对万事亨通\n",
      "孙悟空对紫霞\n",
      "\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '对对联：\\n天对地\\n雨对风\\n大陆对长空\\n雷隐隐对雾蒙蒙\\n开心大吉对万事亨通\\n孙悟空对', 3, 3)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
